{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load data\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "solvers = ['svd', 'lsqr', 'eigen']\n",
    "\n",
    "measures = []\n",
    "\n",
    "for solver in solvers:\n",
    "    # Create an LDA object\n",
    "    if solver == 'svd':\n",
    "        lda_model = LinearDiscriminantAnalysis(solver=solver, shrinkage=None)\n",
    "    else:\n",
    "        lda_model = LinearDiscriminantAnalysis(solver=solver, shrinkage='auto')\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = lda_model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    measures.append({'solver': solver, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  solver  accuracy  precision    recall        f1\n",
      "0    svd  0.805273   0.809213  0.805273  0.806356\n",
      "1   lsqr  0.805339   0.809274  0.805339  0.806423\n",
      "2  eigen  0.805339   0.809274  0.805339  0.806423\n"
     ]
    }
   ],
   "source": [
    "# Print results in a table\n",
    "measures_df = pd.DataFrame(measures)\n",
    "print(measures_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that all solvers reach similar results, and they all have values a little below other methods  \n",
    "Might be because the distribution is not normal, or the covariance matrices are not equal, or even that the decision  \n",
    "boundary is simply not extremely correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Load data\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Create a QDA object\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Train the QDA model\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = qda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall       f1\n",
      "0  0.961042   0.961048  0.961042  0.96101\n"
     ]
    }
   ],
   "source": [
    "measures = []\n",
    "measures.append({'accuracy': metrics.accuracy_score(y_test, y_pred), 'precision': metrics.precision_score(y_test, y_pred, average='weighted'), 'recall': metrics.recall_score(y_test, y_pred, average='weighted'), 'f1': metrics.f1_score(y_test, y_pred, average='weighted')})\n",
    "\n",
    "measures_df = pd.DataFrame(measures)\n",
    "print(measures_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results when using a Quadratic Discriminant are better than the Linear Discriminant,  \n",
    "meaning the decision boundary is not linear (and is quadratic)  \n",
    "Other possible explanation is that the assumption of the equal covariance matrices is wrong"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
